{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ee2f76dad0f4d2b9a0c1f64075fb9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6fbc93f723604728bb6537039c2c6fae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e2e7f47907942f3880ad3ed78249164",
              "IPY_MODEL_be9d109cd1fa4ec0a6420e18d53cfce6"
            ]
          }
        },
        "6fbc93f723604728bb6537039c2c6fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e2e7f47907942f3880ad3ed78249164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b782dea6aa54d6c9262f147ee90337f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c2e6ff6923e4372913535bef7e4fc48"
          }
        },
        "be9d109cd1fa4ec0a6420e18d53cfce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e855c05c0ed54a4daab123bdba39fbee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22164d8d10aa4294a32356b274fccb09"
          }
        },
        "8b782dea6aa54d6c9262f147ee90337f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c2e6ff6923e4372913535bef7e4fc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e855c05c0ed54a4daab123bdba39fbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22164d8d10aa4294a32356b274fccb09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51037781cf2b428a9e5b136e076be516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b10652f710d84701928db1d4840c3e6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cec4a68b3c44b129f3293422ca3d68a",
              "IPY_MODEL_dcfbe2c5ed474f8e8907a6a440efae05"
            ]
          }
        },
        "b10652f710d84701928db1d4840c3e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cec4a68b3c44b129f3293422ca3d68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_22689cfb3d85406ab756462eca97c59a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7255d8f3c274acaa7e195c6184522ef"
          }
        },
        "dcfbe2c5ed474f8e8907a6a440efae05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00ccc3616c80428a87df699f871a5732",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [30:32&lt;00:00, 254B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_326c033e0fe8412cbee0fdc48aab6f36"
          }
        },
        "22689cfb3d85406ab756462eca97c59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7255d8f3c274acaa7e195c6184522ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00ccc3616c80428a87df699f871a5732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "326c033e0fe8412cbee0fdc48aab6f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd282c7a754a4842b0b634fb8d8b73e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ababa7eba18242769caec746934519ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a726f6c93eb84ec38c86baa54f79c415",
              "IPY_MODEL_a16e4cf664094fd6a6f60b550d43233f"
            ]
          }
        },
        "ababa7eba18242769caec746934519ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a726f6c93eb84ec38c86baa54f79c415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06f7f2bd399841c99e189465dac7b0d4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9c61c66b3c2419999caa3ad058a6e84"
          }
        },
        "a16e4cf664094fd6a6f60b550d43233f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9842df9cca54102b78214cf4fe75778",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:13&lt;00:00, 2.04B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e946496a2c38431db747a2787a03028d"
          }
        },
        "06f7f2bd399841c99e189465dac7b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9c61c66b3c2419999caa3ad058a6e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9842df9cca54102b78214cf4fe75778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e946496a2c38431db747a2787a03028d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0670ada34ab34719a46d242a24a92598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_314bc60fd25d43cc85bdfd8d3145b8de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1864f25da02b4e32af85bb062ba14e42",
              "IPY_MODEL_48ed9f438a1245b2a9531f88a084dfc6"
            ]
          }
        },
        "314bc60fd25d43cc85bdfd8d3145b8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1864f25da02b4e32af85bb062ba14e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5627758a98c0432486f48cff07e07ab1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_833fd7a67862451b939409fd51e777b1"
          }
        },
        "48ed9f438a1245b2a9531f88a084dfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd06e53a3cfa44f993cbe31df814bf4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:01&lt;00:00, 328B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e9536413b104055b0940a6fc4d2b577"
          }
        },
        "5627758a98c0432486f48cff07e07ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "833fd7a67862451b939409fd51e777b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd06e53a3cfa44f993cbe31df814bf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e9536413b104055b0940a6fc4d2b577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e4b1622d3b042a1a30588ac44970424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b94841200d744ccbda738c1d73aaf77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3609acc5e1204011b1b717e4e2bacc2e",
              "IPY_MODEL_7a260dfb13b04c7f912314c2bba8ed89"
            ]
          }
        },
        "7b94841200d744ccbda738c1d73aaf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3609acc5e1204011b1b717e4e2bacc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_212f1e5901dc4cdaa14252e1b7c53c5b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3650a390e0b244888afa005c31277cdb"
          }
        },
        "7a260dfb13b04c7f912314c2bba8ed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dab79b32841f42fb8cbf5bed3b707452",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [20:35&lt;00:00, 1.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2d56ccf07814c58ba3468822f78f8f0"
          }
        },
        "212f1e5901dc4cdaa14252e1b7c53c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3650a390e0b244888afa005c31277cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dab79b32841f42fb8cbf5bed3b707452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2d56ccf07814c58ba3468822f78f8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFZLLrZ6ygFr"
      },
      "source": [
        "# COLX 563 Lab Assignment 4: Slot filling\n",
        "## Assignment Objectives\n",
        "\n",
        "In this lab, you will build an end-to-end system for basic (binary) intent recognition and slot filling in the context of a dialogue system. It is a team assignment, and you have nearly complete freedom with regards to your solution, with a few restrictions mentioned below. For this lab, you will work with your capstone team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUVwnHo2ygFs"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "Add imports below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PLday5ygFt"
      },
      "source": [
        "#provided code\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm, trange\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqHQzYs_ylbQ",
        "outputId": "396985e3-73ff-4fff-e2ef-829cd26867e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xBWmeivGRJj",
        "outputId": "b022dc03-3c18-4a00-c5e5-1d9ee6a4157d"
      },
      "source": [
        "manual_seed = 11\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)\n",
        "\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2_kty8tygFu"
      },
      "source": [
        "For this lab, you'll be working with the MultiWOZ dataset of goal-oriented dialogues (2.2). You can look at the full corpus [here](https://github.com/budzianowski/multiwoz/tree/master/data/MultiWOZ_2.2). It has an impressively detailed annotation involving multiple turns and multiple goals which we have simplified to just the initiating request (first turn) and involving two possible intents and the corresponding slots for those intents. Download the data from [github](https://github.ubc.ca/jungyeul/COLX_563_adv-semantics_lab_students/raw/master/Multiwoz.zip), unzip it into a directory outside of your lab repo and change the path below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK9psKfXygFu"
      },
      "source": [
        "#provided code\n",
        "woz_directory =\"/content/drive/MyDrive/Colab Notebooks/COLX_563_lab4/data/\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni685hSWygFv"
      },
      "source": [
        "## Tidy Submission\n",
        "rubric={mechanics:1}\n",
        "\n",
        "To get the marks for tidy submission:\n",
        "- Submit the assignment by filling in this Jupyter notebook with your answers embedded\n",
        "- Be sure to follow the instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ICDNNdygFv"
      },
      "source": [
        "## Inspecting the data\n",
        "\n",
        "Let's look at corresponding pairs of utterances and answers from the training portion of our corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl9QY4GjygFv",
        "outputId": "dfc195b2-1ecf-4c68-e872-473ebc136126"
      },
      "source": [
        "count = 0\n",
        "with open(woz_directory + \"WOZ_train_utt.txt\") as f1:\n",
        "    with open(woz_directory + \"WOZ_train_ans.txt\") as f2:\n",
        "        while count < 20:\n",
        "            print(f1.readline().strip())\n",
        "            print(f2.readline().strip())\n",
        "            print(\"------\")\n",
        "            count += 1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Guten Tag, I am staying overnight in Cambridge and need a place to sleep. I need free parking and internet.\n",
            "find_hotel|hotel-area=centre|hotel-internet=yes|hotel-parking=yes\n",
            "------\n",
            "Hi there! Can you give me some info on Cityroomz?\n",
            "find_hotel|hotel-name=cityroomz\n",
            "------\n",
            "I am looking for a hotel named alyesbray lodge guest house.\n",
            "find_hotel|hotel-name=alyesbray lodge guest house\n",
            "------\n",
            "I am looking for a restaurant. I would like something cheap that has Chinese food.\n",
            "find_restaurant|restaurant-food=chinese|restaurant-pricerange=cheap\n",
            "------\n",
            "I'm looking for an expensive restaurant in the centre if you could help me.\n",
            "find_restaurant|restaurant-area=centre|restaurant-pricerange=expensive\n",
            "------\n",
            "I'm looking for a places to go and see during my upcoming trip to Cambridge.\n",
            "find_hotel\n",
            "------\n",
            "Yeah, could you recommend a good gastropub?\n",
            "find_restaurant|restaurant-food=gastropub\n",
            "------\n",
            "I want to find an expensive restaurant and serves european food. Can i also have the address, phone number and its area. ?\n",
            "find_restaurant|restaurant-food=european|restaurant-pricerange=expensive\n",
            "------\n",
            "Where's a good place to eat crossover food in Cambridge?\n",
            "find_restaurant|restaurant-food=crossover\n",
            "------\n",
            "I need a place to stay that has free wifi.\n",
            "find_hotel|hotel-internet=yes\n",
            "------\n",
            "I am looking for a restaurant that is in the expensive price range and in the south part of town.\n",
            "find_restaurant|restaurant-area=south|restaurant-pricerange=expensive\n",
            "------\n",
            "Can you help me find an expensive Chinese food restaurant?\n",
            "find_restaurant|restaurant-food=chinese|restaurant-pricerange=expensive\n",
            "------\n",
            "I'm looking to go to dinner tonight and am in the mood for some good Bistro in the centre of town, can you find me some options?\n",
            "find_restaurant|restaurant-area=centre|restaurant-food=bistro\n",
            "------\n",
            "I am looking for a particular restaurant. Its name is called travellers rest\n",
            "find_restaurant|restaurant-name=travellers rest\n",
            "------\n",
            "Heya, can you find me an expensive restaurant with north african food?\n",
            "find_restaurant|restaurant-food=african|restaurant-pricerange=expensive\n",
            "------\n",
            "I am looking for a restaurant.\n",
            "find_restaurant\n",
            "------\n",
            "I am looking for a high priced hotel in the north side of town\n",
            "find_hotel|hotel-area=north|hotel-pricerange=expensive\n",
            "------\n",
            "Hi, what can you tell me about the bangkok city restaurant?\n",
            "find_restaurant|restaurant-name=bangkok city\n",
            "------\n",
            "I'm looking for a hotel, can you help?\n",
            "find_hotel|hotel-type=hotel\n",
            "------\n",
            "Please find me a place to dine that's expensive and in the centre.\n",
            "find_restaurant|restaurant-area=centre|restaurant-pricerange=expensive\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAurrldIEcyc"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "with open(woz_directory + \"WOZ_train_utt.txt\") as f1:\n",
        "  for line in f1:\n",
        "    line = line.strip()\n",
        "    X_train.append(line)\n",
        "with open(woz_directory + \"WOZ_train_ans.txt\") as f2:\n",
        "  for line in f2:\n",
        "    line = line.strip()\n",
        "    line_lst = line.split('|')\n",
        "    y_train.append(line_lst[0])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeVK0daDa-r"
      },
      "source": [
        "# X_train"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kNfaWh_OaGI"
      },
      "source": [
        "X_dev = []\n",
        "y_dev = []\n",
        "with open(woz_directory + \"WOZ_dev_utt.txt\") as f1:\n",
        "  for line in f1:\n",
        "    line = line.strip()\n",
        "    X_dev.append(line)\n",
        "with open(woz_directory + \"WOZ_dev_ans.txt\") as f2:\n",
        "  for line in f2:\n",
        "    line = line.strip()\n",
        "    line_lst = line.split('|')\n",
        "    y_dev.append(line_lst[0])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNk0c30RFtNg",
        "outputId": "1617cc92-979d-404d-f391-4459e111dd47"
      },
      "source": [
        "len(X_train) == len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ1of3ExD5gx"
      },
      "source": [
        "# with open(woz_directory + \"train.tsv\", \"w\") as fout:\n",
        "#   for text, label in zip(X_train, y_train):\n",
        "#     fout.write(text + \"\\t\" + label + \"\\n\")\n",
        "\n",
        "# with open(woz_directory + \"dev.tsv\", \"w\") as fout:\n",
        "#   for text, label in zip(X_dev, y_dev):\n",
        "#     fout.write(text + \"\\t\" + label + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t7LeoPYha16"
      },
      "source": [
        "with open(woz_directory + \"test.tsv\", \"w\") as fout:\n",
        "  with open(woz_directory + \"WOZ_test_utt.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      fout.write(line + \"\\t\" + \"find_hotel\" + \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUoIME0FFyZy",
        "outputId": "89963220-27de-4514-94ec-e16b97611aac"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 68.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5xQ86ECGzH0",
        "outputId": "b2d0014f-1135-4c55-8267-ae4a3da19323"
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtOzInFuGvZv"
      },
      "source": [
        "from transformers import *"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TKITrziDHZsW",
        "outputId": "b805f980-51ae-4dbf-cb05-a4a6e7b7ae33"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Guten Tag, I am staying overnight in Cambridge and need a place to sleep. I need free parking and internet.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "2ee2f76dad0f4d2b9a0c1f64075fb9a3",
            "6fbc93f723604728bb6537039c2c6fae",
            "1e2e7f47907942f3880ad3ed78249164",
            "be9d109cd1fa4ec0a6420e18d53cfce6",
            "8b782dea6aa54d6c9262f147ee90337f",
            "9c2e6ff6923e4372913535bef7e4fc48",
            "e855c05c0ed54a4daab123bdba39fbee",
            "22164d8d10aa4294a32356b274fccb09",
            "51037781cf2b428a9e5b136e076be516",
            "b10652f710d84701928db1d4840c3e6a",
            "5cec4a68b3c44b129f3293422ca3d68a",
            "dcfbe2c5ed474f8e8907a6a440efae05",
            "22689cfb3d85406ab756462eca97c59a",
            "a7255d8f3c274acaa7e195c6184522ef",
            "00ccc3616c80428a87df699f871a5732",
            "326c033e0fe8412cbee0fdc48aab6f36",
            "cd282c7a754a4842b0b634fb8d8b73e1",
            "ababa7eba18242769caec746934519ec",
            "a726f6c93eb84ec38c86baa54f79c415",
            "a16e4cf664094fd6a6f60b550d43233f",
            "06f7f2bd399841c99e189465dac7b0d4",
            "f9c61c66b3c2419999caa3ad058a6e84",
            "a9842df9cca54102b78214cf4fe75778",
            "e946496a2c38431db747a2787a03028d"
          ]
        },
        "id": "xRxmWd1bHNXz",
        "outputId": "947aa938-95f7-4ba8-e54b-b5b9e9d0b574"
      },
      "source": [
        "model_path = \"bert-large-uncased\"\n",
        "# define label to number dictionary\n",
        "lab2ind = {'find_hotel': 0, 'find_restaurant': 1}\n",
        "\n",
        "# tokenizer from pre-trained BERT model\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased',do_lower_case=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ee2f76dad0f4d2b9a0c1f64075fb9a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51037781cf2b428a9e5b136e076be516",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd282c7a754a4842b0b634fb8d8b73e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nks1ZjSddKGb"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    # initialization\n",
        "    def __init__(self, data_lst, labels, tokenizer, max_len, lab2ind):\n",
        "        \"\"\"\n",
        "          dataframe: pandas DataFrame.\n",
        "          tokenizer: Hugginfance BERT/RoBERTa tokenizer\n",
        "          max_len: maximal length of input sequence\n",
        "          lab2ind: dictionary of label classes\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        # self.data = dataframe\n",
        "        self.comment_text = data_lst\n",
        "        self.labels = labels\n",
        "        self.max_len = max_len\n",
        "        self.lab2ind = lab2ind\n",
        "\n",
        "    # get the size of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    # generate sample by index\n",
        "    def __getitem__(self, index):\n",
        "        # get ith sample and label\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        label = str(self.labels[index])\n",
        "\n",
        "        label = self.lab2ind[label]\n",
        "        # use encode_plus() of Transformers to tokenize and vectorize input seuqnce and covert it to tensors. \n",
        "        # this method truncate or pad sequence to the maximal length and then return pytorch tensors. \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors = \"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'ids': inputs['input_ids'],\n",
        "            'mask': inputs['attention_mask'],\n",
        "            'targets': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQdpZSl38sOJ"
      },
      "source": [
        "# class CustomDataset(Dataset):\n",
        "#     # initialization\n",
        "#     def __init__(self, dataframe, tokenizer, max_len, lab2ind):\n",
        "#         \"\"\"\n",
        "#           dataframe: pandas DataFrame.\n",
        "#           tokenizer: Hugginfance BERT/RoBERTa tokenizer\n",
        "#           max_len: maximal length of input sequence\n",
        "#           lab2ind: dictionary of label classes\n",
        "#         \"\"\"\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.data = dataframe\n",
        "#         self.comment_text = self.data.content\n",
        "#         self.labels = self.data.label\n",
        "#         self.max_len = max_len\n",
        "#         self.lab2ind = lab2ind\n",
        "\n",
        "#     # get the size of the dataset\n",
        "#     def __len__(self):\n",
        "#         return len(self.comment_text)\n",
        "\n",
        "#     # generate sample by index\n",
        "#     def __getitem__(self, index):\n",
        "#         # get ith sample and label\n",
        "#         comment_text = str(self.comment_text[index])\n",
        "#         label = str(self.labels[index])\n",
        "\n",
        "#         label = self.lab2ind[label]\n",
        "#         # use encode_plus() of Transformers to tokenize and vectorize input seuqnce and covert it to tensors. \n",
        "#         # this method truncate or pad sequence to the maximal length and then return pytorch tensors. \n",
        "#         inputs = self.tokenizer.encode_plus(\n",
        "#             comment_text,\n",
        "#             None,\n",
        "#             add_special_tokens=True,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             max_length=self.max_len,\n",
        "#             return_token_type_ids=False,\n",
        "#             return_tensors = \"pt\"\n",
        "#         )\n",
        "\n",
        "#         return {\n",
        "#             'ids': inputs['input_ids'],\n",
        "#             'mask': inputs['attention_mask'],\n",
        "#             'targets': torch.tensor(label, dtype=torch.long)\n",
        "#         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_x4o31EUzr"
      },
      "source": [
        "def regular_encode(X_train, y_train, tokenizer, lab2ind, shuffle=True, num_workers = 2, batch_size=64, maxlen = 32, mode = 'train'): \n",
        "    '''\n",
        "      file_path: path to your dataset file\n",
        "      tokenizer: tokenizer method\n",
        "      lab2ind: label-to-index dictionary\n",
        "      shuffle: shuffle the dataset or not\n",
        "      num_workers: a number of data processors\n",
        "      batch_size: the number of batch size\n",
        "      maxlen: maximal sequence length\n",
        "      mode: the type of dataset\n",
        "    '''\n",
        "    if we are in train mode, we will load two columns (i.e., text and label).\n",
        "    if mode == 'train':\n",
        "        # Use pandas to load dataset, the dataset should be a tsv file where the first line is the header.\n",
        "        df = pd.read_csv(file_path, delimiter='\\t',header=None, names=['content','label'], encoding='utf-8', quotechar=None, quoting=3)\n",
        "    \n",
        "    # if we are in predict mode, we will load one column (i.e., text).\n",
        "    elif mode == 'predict':\n",
        "        df = pd.read_csv(file_path, delimiter='\\t',header=None, names=['content', 'label'])\n",
        "    else:\n",
        "        print(\"the type of mode should be either 'train' or 'predict'. \")\n",
        "        return\n",
        "        \n",
        "    print(\"{} Dataset: {}\".format(file_path, df.shape))\n",
        "    # instantiate the dataset instance \n",
        "    custom_set = CustomDataset(X_train, y_train, tokenizer, maxlen,lab2ind)\n",
        "    \n",
        "    dataset_params = {'batch_size': batch_size, 'shuffle': shuffle, 'num_workers': num_workers}\n",
        "\n",
        "    batch_data_loader = DataLoader(custom_set, **dataset_params)\n",
        "    # return a data iterator\n",
        "    return batch_data_loader"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyZzOedYNFAe",
        "outputId": "72f85e63-5e34-470d-f56a-16678e90fdd1"
      },
      "source": [
        "tokenizer.encode_plus(X_train[1], add_special_tokens=True, padding='longest', return_token_type_ids=False, max_length=128, return_tensors=\"pt\")['input_ids'][0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  7632,  2045,   999,  2064,  2017,  2507,  2033,  2070, 18558,\n",
              "         2006,  2103,  9954,  2480,  1029,   102])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH1jw3hyEqM4"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "batch_size = 32\n",
        "max_seq_length = 32\n",
        "num_epochs = 5\n",
        "warmup_proportion = 0.1\n",
        "learning_rate = 3e-4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "\n",
        "train_file = os.path.join(woz_directory, \"train.tsv\")\n",
        "dev_file = os.path.join(woz_directory, \"dev.tsv\")\n",
        "test_file = os.path.join(woz_directory, \"test.tsv\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68dnsUWUHwC7"
      },
      "source": [
        "train_dataloader = regular_encode(X_train, y_train, tokenizer, lab2ind, shuffle=True, batch_size=batch_size, maxlen = max_seq_length)\n",
        "validation_dataloader = regular_encode(X_dev,y_dev, tokenizer, lab2ind, shuffle=False, batch_size=batch_size, maxlen = max_seq_length)\n",
        "# test_dataloader = regular_encode(test_file, tokenizer, lab2ind, shuffle=False, batch_size=batch_size, maxlen = max_seq_length)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QovhOvjJOBfF"
      },
      "source": [
        "class Bert_cls(nn.Module):\n",
        "\n",
        "    def __init__(self, lab2ind, model_path, hidden_size):\n",
        "        super(Bert_cls, self).__init__()\n",
        "        self.model_path = model_path\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bert_model = BertModel.from_pretrained(model_path, output_hidden_states=True, output_attentions=True)\n",
        "        \n",
        "        self.label_num = len(lab2ind)\n",
        "        \n",
        "        self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.label_num)\n",
        "\n",
        "    def forward(self, bert_ids, bert_mask):\n",
        "        outputs = self.bert_model(input_ids=bert_ids, attention_mask = bert_mask)\n",
        "        pooler_output = outputs['pooler_output']\n",
        "        attentions = outputs['attentions']\n",
        "        \n",
        "        x = self.dense(pooler_output)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout(x)\n",
        "        fc_output = self.fc(x)\n",
        "\n",
        "        return fc_output, attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04hsKNdYO5xX"
      },
      "source": [
        "dense = nn.Linear(1024, 1024).to(device)\n",
        "dropout = nn.Dropout(0.1).to(device)\n",
        "fc = nn.Linear(1024, 2).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "0670ada34ab34719a46d242a24a92598",
            "314bc60fd25d43cc85bdfd8d3145b8de",
            "1864f25da02b4e32af85bb062ba14e42",
            "48ed9f438a1245b2a9531f88a084dfc6",
            "5627758a98c0432486f48cff07e07ab1",
            "833fd7a67862451b939409fd51e777b1",
            "bd06e53a3cfa44f993cbe31df814bf4a",
            "8e9536413b104055b0940a6fc4d2b577",
            "1e4b1622d3b042a1a30588ac44970424",
            "7b94841200d744ccbda738c1d73aaf77",
            "3609acc5e1204011b1b717e4e2bacc2e",
            "7a260dfb13b04c7f912314c2bba8ed89",
            "212f1e5901dc4cdaa14252e1b7c53c5b",
            "3650a390e0b244888afa005c31277cdb",
            "dab79b32841f42fb8cbf5bed3b707452",
            "f2d56ccf07814c58ba3468822f78f8f0"
          ]
        },
        "id": "ozUe28vVOyHR",
        "outputId": "b41e4a30-ffa1-488f-992d-ae19cf7744d2"
      },
      "source": [
        "bert_model = Bert_cls(lab2ind, 'bert-large-uncased', 1024).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0670ada34ab34719a46d242a24a92598",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e4b1622d3b042a1a30588ac44970424",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTHnLGvOPNwp",
        "outputId": "2880d558-cdde-4b92-9c51-8de30c19eaf5"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(bert_model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 336,193,538 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnqj2M7zPV-i"
      },
      "source": [
        "# Parameters:\n",
        "lr = 2e-5\n",
        "max_grad_norm = 1.0\n",
        "epochs = 3\n",
        "warmup_proportion = 0.1\n",
        "num_training_steps  = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "\n",
        "### In Transformers, optimizer and schedules are instantiated like this:\n",
        "# Note: AdamW is a class from the huggingface library\n",
        "# the 'W' stands for 'Weight Decay\"\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr, correct_bias=False)\n",
        "# schedules\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
        "\n",
        "# We use nn.CrossEntropyLoss() as our loss function. \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um6idJouPZAc"
      },
      "source": [
        "def train(model, iterator, optimizer, scheduler, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        # print(i, batch)\n",
        "        input_ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        input_mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['targets'].to(device, dtype = torch.long)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        # input_ids, input_mask, labels = batch\n",
        "        # print(input_mask.shape)\n",
        "        # print(input_ids.size())\n",
        "        \n",
        "        outputs, _ = model(input_ids.squeeze(1), input_mask)\n",
        "        # print(outputs.shape)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_mask, labels\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.cpu().item()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    # free GPU memory\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz8UsPwXPbgy"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch.values())\n",
        "            # Unpack the inputs from our dataloader\n",
        "            input_ids, input_mask, labels = batch\n",
        "            \n",
        "            outputs,_ = model(input_ids.squeeze(1), input_mask)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # delete used variables to free GPU memory\n",
        "            del batch, input_ids, input_mask\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gm1VeT2PesI"
      },
      "source": [
        "import os\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/COLX_563_lab4/ckpt'\n",
        "if os.path.exists(save_path) == False:\n",
        "    os.makedirs(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbT1jW1lPm-V",
        "outputId": "1db54ddd-e974-4d62-8b14-af16f0af1896"
      },
      "source": [
        "# Train the model\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "    train_loss = train(bert_model, train_dataloader, optimizer, scheduler, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(bert_model, validation_dataloader, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': bert_model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"/content/drive/MyDrive/Colab Notebooks/COLX_563_lab4/ckpt/BERT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss, val_acc, val_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Epoch:  33%|███▎      | 1/3 [01:00<02:01, 60.56s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/3], Train Loss: 0.0011, Validation Loss: 0.0257, Validation Accuracy: 0.9951, Validation F1: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:  67%|██████▋   | 2/3 [02:05<01:01, 61.82s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/3], Train Loss: 0.0009, Validation Loss: 0.0257, Validation Accuracy: 0.9951, Validation F1: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch: 100%|██████████| 3/3 [03:10<00:00, 63.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/3], Train Loss: 0.0009, Validation Loss: 0.0257, Validation Accuracy: 0.9951, Validation F1: 0.9951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtachFLxgaEQ",
        "outputId": "f33581bc-bbd8-49a4-b9dc-28ddfa09c40e"
      },
      "source": [
        "\n",
        "\n",
        "test_dataloader = regular_encode(woz_directory + \"test.tsv\", tokenizer, lab2ind, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/COLX_563_lab4/data/test.tsv Dataset: (400, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YjbjgnOiqN5"
      },
      "source": [
        "all_pred = []\n",
        "# all_probs = []\n",
        "softmax = nn.Softmax(dim=1)\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch.values())\n",
        "        # Unpack the inputs from our dataloader\n",
        "        input_ids, input_mask, labels = batch\n",
        "\n",
        "        outputs,_ = bert_model(input_ids.squeeze(1), input_mask.squeeze(1))\n",
        "        \n",
        "\n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_mask\n",
        "\n",
        "        # identify the predicted class for each example in the batch\n",
        "        prob_dist = softmax(outputs.cpu().data)\n",
        "        _, predicted = torch.max(prob_dist, 1)\n",
        "        # put all the true labels and predictions to two lists\n",
        "        all_pred.extend(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j609MDgBjx_H"
      },
      "source": [
        "ind2label = {0: 'find_hotel', 1: 'find_restaurant'}\n",
        "i = 0\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/COLX_563_lab4/data/WOZ_test_ans_predict.txt', \"w\") as fout:\n",
        "  for pred in all_pred:\n",
        "    fout.write(ind2label[int(pred)]+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZwfU1PKmEMw",
        "outputId": "922e9227-0508-4650-945f-f589dcb3bf8b"
      },
      "source": [
        "len(all_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enIGxVOrygFw"
      },
      "source": [
        "The utterances consists of a request for information about either hotels or restaurants. The first part of the answer starts with the intent (either find_restaurant or find_hotel) and then lists the slots that have been filled in based on the utterance. Your goal is to generate this string of intents and slots based purely on the utterance. A few things to note:\n",
        "\n",
        "* Not all slots are filled in, and sometimes there are no slots filled in at all (but there is always an intent).\n",
        "* There are a fixed number of slots for each intent, and they always appear in a particular order, when they are filled in\n",
        "* The slot values sometimes but do not always correspond to what appears in the utterance. For example, a mention of wanting wifi in the request becomes hotel-internet=yes.\n",
        "\n",
        "We will be evaluating based on exact duplication of the entire output string, so before you start coding a solution, you should look carefully at examples in the training set and make sure you understand all the different components of the output, and how they related to the input utterance. In particular, you should identify the various constituent parts of the task, and judge which are likely to be easy, and which are likely to be more difficult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlfTbPfZygFw"
      },
      "source": [
        "## Solution\n",
        "rubric={accuracy:10,quality:5,efficiency:3}\n",
        "\n",
        "You will build a system that, when provided with an utterance, predicts the appropriate intent and slots in the format used in the provided answers. This is an open-ended problem and you may solve it however you like, with the following restrictions:\n",
        "\n",
        "* Your solution should include at least one of token-level prediction models used in Labs 1-3 of this course, i.e. you should make use of a CRF, an LSTM, or a BERT model. You may use multiple models.\n",
        "* You may use basic NLP tools (tokenizer, POS, parser) and unsupervised resources such as word embeddings, but you should NOT use an existing NER system, or any additional labeled data for this task.\n",
        "* Your solution should be appropriately decomposed into parts, and documented. This is a complex enough problem that you should have several functions. You may wrap things up into a single class if you like, but you don't have to.\n",
        "* Use the provided assert to test `dev_predicted`, the output of your complete model on the dev set, you will need to pass the assert to get full accuracy points. \n",
        "* Though you may use dev *accuracy* to guide the development of your model, you should not look at either utterances or answers for the dev (or the test) when developing your model. Limit your inspection of the data (e.g. for the purposes of error analysis) to the training set.\n",
        "\n",
        "Other things to consider:\n",
        "\n",
        "* You may want to build \"standard\" (non-sequential) ML classifiers for some aspects of this problem, but you don't have to!\n",
        "* You may want to use appropriate lexicons. You can build them yourself, or find some.\n",
        "* Rather than using statistical classifiers, you may want to use rule-based methods to solve some of the problems you're facing.\n",
        "* You should probably do regular error analysis, some kind of crossvalidation in the training set is a good approach for this, or you can create another (inspectable) internal dev set by splitting up the training set.\n",
        "* If you're looking for just a little bit more performance, don't forget to tune your hyperparameters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5uas1JsygFx"
      },
      "source": [
        "## Report\n",
        "rubric={raw:2,reasoning:3,writing:1}\n",
        "\n",
        "Describe your system, and discuss what your thinking about particular choices and any experiments you tried. Please talk about things you tried but didn't work, or things you thought of doing but didn't. Finally, discuss how each group member contributed to the project. As usual, there is an expectation that every group member will have made some significant contribution to the project. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrV_DTwbygFx"
      },
      "source": [
        "## Submit to Kaggle \n",
        "rubric={accuracy:2}\n",
        "\n",
        "Run your system over the test data, and submit the result (in the same format as the train/dev answers) to the Kaggle competition. The competition is hosted [here](https://www.kaggle.com/c/mds-cl-2020-21-colx-563-lab-assignment-4). To get full points, you need to beat the public baseline. Use your capstone partner as your team name please!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9OSfy1QygFy"
      },
      "source": [
        "## Exercise: Kaggle competition (Optional)\n",
        "rubric={raw:2}\n",
        "\n",
        "As a team, compete to get the best result in the task. Since there are only 8 teams, the distribution of marks is a bit different than usual, only the top 3 groups will get bonus points. As usual, the rankings will be based on the score on the private leaderboard:\n",
        "\n",
        "\n",
        "- 1st place: 2\n",
        "- 2nd place: 1\n",
        "- 3rd place: 0.5"
      ]
    }
  ]
}